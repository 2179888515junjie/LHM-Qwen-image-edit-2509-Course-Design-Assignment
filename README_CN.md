<h1 align="center">
  <img src="/assets/bucea.jpg">
  <br>
  åŸºäº LHM ä¸ Qwen æ¨¡å‹çš„ä¸‰ç»´æ•°å­—äººç”Ÿæˆ 
</h1>

<p align="center">
  <strong>SiYu Liao<sup>*</sup></strong><br>
  åŒ—äº¬å»ºç­‘å¤§å­¦
</p>

[![é¡¹ç›®ä¸»é¡µ](https://img.shields.io/badge/ğŸŒ-é¡¹ç›®ä¸»é¡µ-blueviolet)](https://github.com/2179888515junjie/LHM-Qwen-image-edit-2509-Course-Design-Assignment)



## ğŸ“¢ æœ€æ–°åŠ¨æ€
**[2025å¹´11æœˆ24æ—¥]** æˆ‘å¼€å§‹äº†è¿™ä¸ªè¯¾è®¾ readme çš„ç¼–å†™<br>
**[2025å¹´11æœˆ23æ—¥]** æˆ‘æˆåŠŸå®Œæˆäº†æœ¬åœ° Qwen-Image-Edit-2059 æ¨¡å‹éƒ¨ç½²ä»¥åŠåˆ†å¸ƒåŸºäº2å—48Gæ˜¾å­˜GPUç”Ÿæˆä»£ç <br>
**[2025å¹´11æœˆ19æ—¥]** æˆ‘æˆåŠŸå®Œæˆäº†åŸºäº Qwen-Image API æ¥å£è°ƒç”¨æ¨¡å‹ LHM ç”Ÿæˆä»£ç <br>



## âš™ï¸ ç¯å¢ƒé…ç½®

æœ¬é¡¹ç›®åŸºäº **ä¸¤ä¸ªç‹¬ç«‹è™šæ‹Ÿç¯å¢ƒ**ï¼ˆ`LHM_base` ä¸ `qwen_img`ï¼‰ï¼ŒåŸå› ï¼š

- **LHM æ¨¡å‹ä¾èµ–æ—§ç‰ˆ diffusers / accelerate / mmcv / pytorch3d**
- **Qwen-Image-Edit-2509 æœ¬åœ°æ¨ç†ä¾èµ–æœ€æ–° diffusers / transformers / accelerate**
- ä¸¤è€…ä¾èµ–å¼ºå†²çªï¼Œå› æ­¤å¿…é¡»åˆ†ç¯å¢ƒè¿è¡Œã€‚

æ­¤å¤–ï¼Œç”±äº **Qwen-Image-Edit-2509 æœ¬åœ°æ¨¡å‹ä½“é‡å·¨å¤§ï¼ˆâ‰ˆ57 GBï¼‰**ï¼Œéœ€è¦é«˜æ˜¾å­˜ GPU æ”¯æŒã€‚

æœ¬é¡¹ç›®å®é™…è¿è¡Œç¯å¢ƒå¦‚ä¸‹ï¼š

### ğŸ–¥ï¸ ç¡¬ä»¶ç¯å¢ƒï¼ˆAutoDL äº‘ç«¯ï¼‰
| è®¾å¤‡ | å‹å· | æ˜¾å­˜ | æ•°é‡ |
|------|------|------|------|
| GPU | NVIDIA vGPU-48GB | 49 GB | 2 å¼  |
| CUDA ç‰ˆæœ¬ | CUDA 13.0 | - | é©±åŠ¨ 580.76.05 |
| CPU | AutoDL é»˜è®¤é…ç½® | - | - |
| ç³»ç»Ÿ | Ubuntu 20.04 / Miniconda | - | - |
> ğŸ’¡ **è¯´æ˜ï¼š**  
>ç”±äºåŸºäºAutodlï¼Œä»£ç ä¸­éƒ¨åˆ†è·¯å¾„åŒ…å«Autodl-tmpï¼Œå¯ä»¥æŒ‰éœ€æ›´æ”¹æ–‡ä»¶å  
> LHM-1B / LHM-500M åœ¨æœ¬æœºä¸¤å¼  48GB GPU ä¸Šå‡å¯ç¨³å®šè¿è¡Œï¼›  
> Qwen-Image-Edit-2509ï¼ˆæœ¬åœ°ç‰ˆï¼‰æ¨ç†éœ€è¦å•å¡è‡³å°‘ **48GB æ˜¾å­˜** æ‰èƒ½å®Œå…¨åŠ è½½æ¨¡å‹ã€‚
> é‡‡ç”¨æœ¬åœ°æ¨ç†æ—¶å ç”¨æ˜¾å­˜æ•°æ®å¦‚ä¸‹å›¾æ‰€ç¤º
  
<img src="./assets/xiancun.png" />
  

1.å…‹éš†ä»“åº“
```bash
git clone https://github.com/2179888515junjie/LHM-Qwen-image-edit-2509-Course-Design-Assignment
cd LHM-Qwen-image-edit-2509-Course-Design-Assignment

```

2.åˆ›å»ºç¯å¢ƒ1ï¼šLHM_baseï¼ˆä¸»ç¯å¢ƒï¼‰  
  
 æ­¤ç¯å¢ƒç”¨äºè¿è¡Œï¼š  
> LHM æ¨¡å‹ï¼ˆ1B / 500Mï¼‰  
> SAM2 åˆ†å‰²  
> è§†é¢‘è§£æï¼ˆVideo2MotionPipelineï¼‰  
> 3DGS é‡å»ºä¸æ¸²æŸ“  
 
**åˆ›å»ºç¯å¢ƒ**
```
conda create -n LHM_base python=3.10
conda activate LHM_base
```

å®‰è£… LHM ä¾èµ–ï¼ˆé€‚é… CUDA 11.8ï¼‰

```
# CUDA 11.8 ç¯å¢ƒ
sh ./install_cu118.sh
pip install rembg

æˆ– CUDA 12.xï¼š

# cuda 12.1
sh ./install_cu121.sh
pip install rembg
```
æœ¬ç¯å¢ƒä½¿ç”¨çš„å…³é”®åº“ç‰ˆæœ¬ï¼š

> torch==2.3.0+cu118  
> diffusers==0.36.0.dev0  
> mmcv / mmpose / pytorch3d  
> SAM2 (pip install sam-2)  
> accelerate==0.25  
> numpy==1.23.5

æ­¤ç¯å¢ƒå·²ç»è¿‡ 48GB GPUã€CUDA 11.8 å®æµ‹éªŒè¯ï¼Œå¯ç¨³å®šè¿è¡Œ LHM Pipelineã€‚


3.åˆ›å»ºç¯å¢ƒ2ï¼šqwen_imgï¼ˆç”¨äºæœ¬åœ° Qwen-Image-Edit-2509 æ¨ç†ï¼‰

**åˆ›å»ºç¯å¢ƒ**  
<span style="color:yellow">å¼ºçƒˆå»ºè®®é‡‡ç”¨ Qwen å®˜æ–¹æ¨èçš„ diffusers</span>

```
conda create -n qwen_img python=3.10
conda activate qwen_img
```

å®‰è£… Qwen-Image-Edit-2509 æ¨ç†æ‰€éœ€ä¾èµ–ï¼š
```
pip install torch==2.4.0+cu118 torchvision==0.19.0+cu118 --extra-index-url https://download.pytorch.org/whl/cu118

# æœ€æ–° diffusersï¼ˆQwen æ‰€è¦æ±‚ï¼‰
pip install git+https://github.com/huggingface/diffusers

# transformers / accelerate
pip install transformers accelerate

pip install safetensors pillow
```
**è‹¥å‡ºç°"TypeError: scaled_dot_product_attention() got an unexpected keyword argument 'enable_gqa'"æŠ¥é”™**  
å¦‚æœä¸æƒ³æ”¹ç¯å¢ƒç‰ˆæœ¬çš„è¯ï¼Œå¯ä»¥æ‰“ä¸ªè¡¥ä¸ï¼Œæš‚æ—¶ç¦ç”¨å‚æ•°ï¼š 
> import torch.nn.functional as F
> original_scaled_dot_product_attention = F.scaled_dot_product_attention  
> def patched_scaled_dot_product_attention(*args, **kwargs):  
> ç§»é™¤ enable_gqa å‚æ•°  
> kwargs.pop('enable_gqa', None)  
> return original_scaled_dot_product_attention(*args, **kwargs)   
> F.scaled_dot_product_attention = patched_scaled_dot_product_attention



### LHMæ¨¡å‹ä¸‹è½½ 


<span style="color:red">å¦‚æœä½ æ²¡ä¸‹è½½æ¨¡å‹ï¼Œæ¨¡å‹å°†ä¼šè‡ªåŠ¨ä¸‹è½½</span>


| æ¨¡å‹ | è®­ç»ƒæ•°æ® | Transformer å±‚æ•°| ModelScope| HuggingFace| æ¨ç†æ—¶é—´ | è¦æ±‚è¾“å…¥|
| :--- | :--- | :--- | :--- | :--- | :--- |:--- |
| LHM-MINI | 300K è§†é¢‘æ•°æ® + 5K 3Dæ•°æ®  | 2 | [ModelScope](https://modelscope.cn/models/Damo_XR_Lab/LHM-MINI) |[huggingface](https://huggingface.co/3DAIGC/LHM-MINI)| 1.41 s | å…¨èº«åŠèº«|
| LHM-500M | 300K è§†é¢‘æ•°æ® + 5K 3Dæ•°æ®  | 5 | [ModelScope](https://modelscope.cn/models/Damo_XR_Lab/LHM-500M) |[huggingface](https://huggingface.co/3DAIGC/LHM-500M)| 2.01 s | å…¨èº«|
| LHM-500M-HF | 300K è§†é¢‘æ•°æ® + 5K 3Dæ•°æ® | 5 | [ModelScope](https://modelscope.cn/models/Damo_XR_Lab/LHM-500M-HF) |[huggingface](https://huggingface.co/3DAIGC/LHM-500M-HF)| 2.01 s | å…¨èº«åŠèº«|
| LHM-1.0B | 300K è§†é¢‘æ•°æ® + 5K 3Dæ•°æ® | 15 | [ModelScope](https://modelscope.cn/models/Damo_XR_Lab/LHM-1B) |[huggingface](https://huggingface.co/3DAIGC/LHM-1B)| 6.57 s | å…¨èº«|
| LHM-1B-HF | 300K è§†é¢‘æ•°æ® + 5K 3Dæ•°æ®  | 15 | [ModelScope](https://modelscope.cn/models/Damo_XR_Lab/LHM-1B-HF) |[huggingface](https://huggingface.co/3DAIGC/LHM-1B-HF)| 6.57 s |å…¨èº«åŠèº«|



#### ä»HuggingFaceä¸‹è½½
```python
from huggingface_hub import snapshot_download 
# MINI Model
model_dir = snapshot_download(repo_id='3DAIGC/LHM-MINI', cache_dir='./pretrained_models/huggingface')
# 500M-HF Model
model_dir = snapshot_download(repo_id='3DAIGC/LHM-500M-HF', cache_dir='./pretrained_models/huggingface')
# 1B-HF Model
model_dir = snapshot_download(repo_id='3DAIGC/LHM-1B-HF', cache_dir='./pretrained_models/huggingface')
```

### ä¸‹è½½å…ˆéªŒæ¨¡å‹æƒé‡
```bash
# ä¸‹è½½å…ˆéªŒæ¨¡å‹æƒé‡
wget https://virutalbuy-public.oss-cn-hangzhou.aliyuncs.com/share/aigc3d/data/LHM/LHM_prior_model.tar 
tar -xvf LHM_prior_model.tar 
```

### åŠ¨ä½œæ•°æ®å‡†å¤‡
LHM æä¾›äº†æµ‹è¯•åŠ¨ä½œç¤ºä¾‹ï¼š
```bash
# ä¸‹è½½å…ˆéªŒæ¨¡å‹æƒé‡
wget https://virutalbuy-public.oss-cn-hangzhou.aliyuncs.com/share/aigc3d/data/LHM/motion_video.tar
tar -xvf ./motion_video.tar 
```

ä¸‹è½½å®ŒæˆåLHMæ–‡ä»¶ç»“æ„å¦‚ä¸‹ï¼š
```bash
â”œâ”€â”€ configs
â”‚   â”œâ”€â”€ inference
â”‚   â”œâ”€â”€ accelerate-train-1gpu.yaml
â”‚   â”œâ”€â”€ accelerate-train-deepspeed.yaml
â”‚   â”œâ”€â”€ accelerate-train.yaml
â”‚   â””â”€â”€ infer-gradio.yaml
â”œâ”€â”€ engine
â”‚   â”œâ”€â”€ BiRefNet
â”‚   â”œâ”€â”€ pose_estimation
â”‚   â”œâ”€â”€ SegmentAPI
â”œâ”€â”€ example_data
â”‚   â””â”€â”€ test_data
â”œâ”€â”€ exps
â”‚   â”œâ”€â”€ releases
â”œâ”€â”€ LHM
â”‚   â”œâ”€â”€ datasets
â”‚   â”œâ”€â”€ losses
â”‚   â”œâ”€â”€ models
â”‚   â”œâ”€â”€ outputs
â”‚   â”œâ”€â”€ runners
â”‚   â”œâ”€â”€ utils
â”‚   â”œâ”€â”€ launch.py
â”œâ”€â”€ pretrained_models
â”‚   â”œâ”€â”€ dense_sample_points
â”‚   â”œâ”€â”€ gagatracker
â”‚   â”œâ”€â”€ human_model_files
â”‚   â”œâ”€â”€ sam2
â”‚   â”œâ”€â”€ sapiens
â”‚   â”œâ”€â”€ voxel_grid
â”‚   â”œâ”€â”€ arcface_resnet18.pth
â”‚   â”œâ”€â”€ BiRefNet-general-epoch_244.pth
â”œâ”€â”€ scripts
â”‚   â”œâ”€â”€ exp
â”‚   â”œâ”€â”€ convert_hf.py
â”‚   â””â”€â”€ upload_hub.py
â”œâ”€â”€ tools
â”‚   â”œâ”€â”€ metrics
â”œâ”€â”€ train_data
â”‚   â”œâ”€â”€ example_imgs
â”‚   â”œâ”€â”€ motion_video
â”œâ”€â”€ inference.sh
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
```

### Qwen-Image-Edit-2509æ¨¡å‹ä¸‹è½½ 
```python
from huggingface_hub import snapshot_download

# Qwen-Image-Edit-2509ï¼ˆå®Œæ•´ç‰ˆæ¨¡å‹ï¼Œçº¦ 57GBï¼‰
model_dir = snapshot_download(
    repo_id='Qwen/Qwen-Image-Edit-2509',
    cache_dir='./pretrained_models/Qwen-Image-Edit-2509'
)
```

ä¸‹è½½å®ŒæˆåQwen-Image-Edit-2509æ¨¡å‹æ–‡ä»¶ç»“æ„å¦‚ä¸‹ï¼š
```bash
Qwen-Image-Edit-2509
â”œâ”€â”€ processor
â”‚   â”œâ”€â”€ added_tokens.json
â”‚   â”œâ”€â”€ chat_template.jinja
â”‚   â”œâ”€â”€ merges.txt
â”‚   â”œâ”€â”€ preprocessor_config.json
â”‚   â”œâ”€â”€ special_tokens_map.json
â”‚   â”œâ”€â”€ tokenizer.json
â”‚   â”œâ”€â”€ tokenizer_config.json
â”‚   â”œâ”€â”€ video_preprocessor_config.json
â”‚   â””â”€â”€ vocab.json
â”‚
â”œâ”€â”€ scheduler
â”‚   â””â”€â”€ scheduler_config.json
â”‚
â”œâ”€â”€ text_encoder
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ generation_config.json
â”‚   â”œâ”€â”€ model.safetensors.index.json
â”‚   â”œâ”€â”€ model-00001-of-00004.safetensors   # 4.97 GB
â”‚   â”œâ”€â”€ model-00002-of-00004.safetensors   # 4.99 GB
â”‚   â”œâ”€â”€ model-00003-of-00004.safetensors   # 4.93 GB
â”‚   â””â”€â”€ model-00004-of-00004.safetensors   # 1.69 GB
â”‚
â”œâ”€â”€ tokenizer
â”‚   â”œâ”€â”€ added_tokens.json
â”‚   â”œâ”€â”€ chat_template.jinja
â”‚   â”œâ”€â”€ merges.txt
â”‚   â”œâ”€â”€ special_tokens_map.json
â”‚   â”œâ”€â”€ tokenizer_config.json
â”‚   â””â”€â”€ vocab.json
â”‚
â”œâ”€â”€ transformer
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ diffusion_pytorch_model.safetensors.index.json
â”‚   â”œâ”€â”€ diffusion_pytorch_model-00001-of-00005.safetensors   # 9.97 GB
â”‚   â”œâ”€â”€ diffusion_pytorch_model-00002-of-00005.safetensors   # 9.99 GB
â”‚   â”œâ”€â”€ diffusion_pytorch_model-00003-of-00005.safetensors   # 9.99 GB
â”‚   â”œâ”€â”€ diffusion_pytorch_model-00004-of-00005.safetensors   # 9.93 GB
â”‚   â””â”€â”€ diffusion_pytorch_model-00005-of-00005.safetensors   # 0.98 GB
â”‚
â”œâ”€â”€ vae
â”‚   â”œâ”€â”€ config.json
â”‚   â””â”€â”€ diffusion_pytorch_model.safetensors   # 254 MB
â”‚
â”œâ”€â”€ model_index.json
â”œâ”€â”€ .gitattributes
â””â”€â”€ README.md
```

## ğŸ“ƒ æ–‡ä»¶è·¯å¾„

>è¯·ä¿æŒè·¯å¾„å’Œä¸‹é¢ä¸€è‡´  
>æ¨¡å‹æœ¬èº«å†…å®¹è¿›è¡Œçœç•¥
>ä¸»è¦å·¥ä½œæ–‡ä»¶å·²ç»ç”±âœ…ï¸æ ‡å‡º
```bash
Autodl-tmp
â”œâ”€â”€ LHM                                  # ğŸŸ© æœ¬è¯¾è®¾çš„ä¸»å·¥ç¨‹
â”‚   â”œâ”€â”€ qwen_2509.py                     # âœ…ï¸ Qwen æœ¬åœ°è°ƒç”¨è„šæœ¬
â”‚   â”œâ”€â”€ Qwen_API.py                      # âœ…ï¸ Qwen APIç‰ˆæœ¬
â”‚   â”œâ”€â”€ bucea.jpg                        # BUCEA Logo
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ LICENSE
â”‚   â”œâ”€â”€ README.md
â”‚   â”‚
â”‚   â”œâ”€â”€ LHM                              # LHM æ ¸å¿ƒä»£ç 
â”‚   â”‚   â”œâ”€â”€ datasets
â”‚   â”‚   â”œâ”€â”€ losses
â”‚   â”‚   â”œâ”€â”€ models
â”‚   â”‚   â”œâ”€â”€ runners
â”‚   â”‚   â”œâ”€â”€ utils
â”‚   â”‚   â””â”€â”€ launch.py
â”‚   â”‚
â”‚   â”œâ”€â”€ engine                     
â”‚   â”‚   â”œâ”€â”€ BiRefNet                     #è‹¥æœªé‡‡ç”¨Samåˆ™ä½¿ç”¨BiRefNet
â”‚   â”‚   â”œâ”€â”€ pose_estimation
â”‚   â”‚   â””â”€â”€ SegmentAPI                   # SAM2 ç›¸å…³
â”‚   â”‚
â”‚   â”œâ”€â”€ pretrained_models                # æ‰€æœ‰æ¨¡å‹æƒé‡
â”‚   â”‚   â”œâ”€â”€ Damo_XR_Lab
â”‚   â”‚   â”œâ”€â”€ 3DAIGC
â”‚   â”‚   â”œâ”€â”€ sam2
â”‚   â”‚   â”œâ”€â”€ gagatracker
â”‚   â”‚   â”œâ”€â”€ sapiens
â”‚   â”‚   â”œâ”€â”€ human_model_files
â”‚   â”‚   â””â”€â”€ voxel_grid
â”‚   â”‚
â”‚   â”œâ”€â”€ train_data                       # è¾“å…¥å›¾ç‰‡ / åŠ¨ä½œè§†é¢‘
â”‚   â”‚   â”œâ”€â”€ example_imgs
â”‚   â”‚   â””â”€â”€ motion_video
â”‚   â”‚
â”‚   â”œâ”€â”€ outputs
â”‚   â”‚   â”œâ”€â”€ ply                          # ç”Ÿæˆçš„ 3D Gaussian PLY
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚
â”‚   â”œâ”€â”€ configs
â”‚   â”œâ”€â”€ scripts
â”‚   â””â”€â”€ tools
â”‚
â”‚
â”œâ”€â”€ Qwen-Image-Edit-2509                 # ğŸŸ¦ æœ¬åœ° Qwen æ¨¡å‹ï¼ˆ57GBï¼‰
â”‚   â”œâ”€â”€ Qwen_inpaint.py                  # âœ…ï¸ æœ¬åœ°ç”Ÿå›¾å…¥å£ï¼Œè¢« LHM è°ƒç”¨
â”‚   â”œâ”€â”€ processor/
â”‚   â”œâ”€â”€ scheduler/
â”‚   â”œâ”€â”€ text_encoder/
â”‚   â”œâ”€â”€ tokenizer/
â”‚   â”œâ”€â”€ transformer/
â”‚   â”œâ”€â”€ vae/
â”‚   â””â”€â”€ model_index.json
â”‚
â”‚
â”œâ”€â”€ sam2-main/                           # SAM2 å®˜æ–¹ä»“åº“ï¼ˆç”¨äº Segmentï¼‰
â”œâ”€â”€ diffusers-main/                      # HuggingFace diffusers å…¨ä»“åº“
â”œâ”€â”€ pytorch3d-main/                      # PyTorch3Dï¼ˆLHM ä¾èµ–ï¼‰
â”œâ”€â”€ BasicSR-master/
â”œâ”€â”€ CLIP-main/
â”œâ”€â”€ diff-gaussian-rasterization-main/
â”œâ”€â”€ qwen_image_edit_api.py               # âœ…ï¸ è°ƒç”¨APIè„šæœ¬ï¼Œè¯·è¾“å…¥è‡ªå·±çš„API
â””â”€â”€ tools/
```
## ğŸ’» æœ¬åœ°éƒ¨ç½² 
æˆ‘ä»¬ç°åœ¨æ”¯æŒç”¨æˆ·è°ƒç”¨é˜¿é‡Œ Qwen-Image APIæ¥ç”Ÿæˆå›¾ç‰‡ï¼Œåªéœ€è¦ç”¨æˆ·åœ¨"qwen_image_edit_api.py"æ–‡ä»¶ä¸­ï¼Œå†™å…¥è‡ªå·±çš„APIkeyã€‚  
ç”³è¯·é“¾æ¥ï¼šhttps://cn.aliyun.com/product/tongyi?from_alibabacloud=&utm_content=se_1021898286
```bash
# è°ƒç”¨Qwen_APIç”Ÿæˆå›¾ç‰‡
python ./Qwen_API.py 
# è°ƒç”¨æœ¬åœ°Qwenæ¨¡å‹ç”Ÿæˆå›¾ç‰‡
python ./Qwen_2509.py  
```

## ğŸ‘€ æ•ˆæœä¸å±•ç¤º
ä¸‹å›¾ä¸ºè¿è¡Œ Qwen_API.py   
åŸºäºQwen-Image API ç”Ÿæˆçš„å›¾ç‰‡ä¸ç»è¿‡ Sam2 åˆ†å‰²åçš„ç»“æœ
  
<img src="./assets/QwenAPi.png" />

ä¸‹å›¾ä¸ºè¿è¡Œ Qwen_2509.py
åŸºäºQwen-Image-Edit-2509 ç”Ÿæˆçš„å›¾ç‰‡ä¸ç»è¿‡ Sam2 åˆ†å‰²åçš„ç»“æœ
  
<img src="./assets/Qwen2509.png" />  
  
å¯ä»¥çœ‹åˆ°ï¼Œé‡‡ç”¨äº†æ‰©æ•£æ¨¡å‹å¯¹åŸæœ¬è¾“å…¥æ–‡ä»¶è¿›è¡Œé¢„å¤„ç†åï¼Œæ•ˆæœæ˜æ˜¾æå‡äº†  
ä¸‹å›¾ä¸ºå¯¹æ¯”å®éªŒ  
  

<img src="./assets/ablation1.png" />  
  
å¯ä»¥çœ‹åˆ°é‡‡ç”¨äº† Qwen æ¨¡å‹ä¹‹åçš„ç”Ÿæˆè´¨é‡æ˜¯æœ€é«˜çš„  


ä¸‹å›¾ä¸ºæ¶ˆèå®éªŒ  
  
  <img src="./assets/ablation2.png" />  
  
  å¯ä»¥çœ‹åˆ°é‡‡ç”¨ Sam2 + Qwemæ¨¡å‹ è¿›è¡Œåˆ†å‰²ä¸é¢„å¤„ç†çš„æ•ˆæœæ˜¯æœ€ä½³çš„


## ğŸ¤” å±•æœ›
å…¶å®å¯ä»¥å‘ç°ï¼Œæœ¬ä»»åŠ¡çš„åˆè¡·æ˜¯æƒ³ä¼˜åŒ– LHM ç”Ÿæˆ3Dæ•°å­—äººçš„é²æ£’æ€§  
æœ¬å®éªŒå…¶å®è¿˜åšäº†åŸºäºsdv-1.5æ‰©æ•£æ¨¡å‹çš„å°è¯•ï¼Œä½†æ˜¯æ•ˆæœå®å±ä¸ä½³  
åœ¨å¼•å…¥äº† Qwen-Image-Edit-2509 çš„æƒ…å†µä¸‹ï¼Œå®éªŒçš„ç”Ÿæˆæ•ˆæœå¤§å¹…æå‡ï¼Œä½†åŒæ—¶ä¹Ÿå¸¦æ¥äº†ä¸è¶³  
â‘  ç”Ÿæˆæ—¶é—´å¢é•¿  
â‘¡ å ç”¨æ˜¾å­˜è¾ƒé«˜  
æœªæ¥çš„ç ”ç©¶å¯ä»¥è€ƒè™‘ä¸€ä¸ªæ€§èƒ½ä¸ä»£ä»·å‡è¡¡çš„æ–¹å¼å°†è¾“å…¥çš„å›¾ç‰‡ä¼˜åŒ–  


## è‡´è°¢

æœ¬å·¥ä½œåŸºäºä»¥ä¸‹ä¼˜ç§€ç ”ç©¶æˆæœå’Œå¼€æºé¡¹ç›®æ„å»ºï¼š

- [LHM](https://github.com/aigc3d/LHM)
- [IDOL](https://yiyuzhuang.github.io/IDOL/)
